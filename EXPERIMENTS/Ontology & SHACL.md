# Ontology-Driven GraphRAG: A Pipeline for Knowledge Extraction, Validation, and Interrogation

Этот проект представляет собой комплексный пайплайн для построения и использования базы знаний (Knowledge Graph) на основе неструктурированных текстовых данных. Ключевой особенностью является **онтологическое управление** (Ontology-Driven approach), где заранее определенная онтология и формальные правила (SHACL) направляют процессы извлечения, валидации и запроса данных.

Пайплайн демонстрирует современные подходы из области GraphRAG, включая формальную верификацию целостности графа и диалоговую оценку качества ответов, основанную на методологии **MTRAGEval**.

## Ключевые особенности

*   **Онтологический каркас**: Использование базовой онтологии (TTL) для определения схемы данных (классы, свойства) и SHACL для задания ограничений целостности.
*   **LLM-based Triple Extraction**: Извлечение RDF-триплетов из текста с помощью LLM (GPT-4o-mini) в строго структурированном JSON-формате.
*   **Формальная валидация**:
    *   **SHACL**: Проверка графа на соответствие заданным правилам (например, «у каждого дрона должна быть хотя бы одна способность»).
    *   **OWL Reasoner (Pellet)**: Анализ логической консистентности онтологии и выявление противоречий.
*   **GraphRAG для Q&A**: Реализация легковесного механизма "вопрос-ответ", который:
    1.  Находит релевантные сущности в графе (Entity Linking).
    2.  Извлекает подграф в качестве контекста (Subgraph Retrieval).
    3.  Генерирует ответ, основанный **только** на фактах из графа, с цитированием источников (Grounded Generation).
*   **Интеграция с Neo4j**: Возможность загрузки построенного графа в графовую СУБД Neo4j для персистентного хранения и сложных запросов.
*   **Систематическая оценка**: Использование методологии, вдохновленной **MTRAGEval**, для оценки качества retrieval-компонента и "заземленности" (groundedness) ответов.

## Структура пайплайна

Код в файле `ontology.py` последовательно выполняет 7 основных шагов:

### 1. Определение онтологии, SHACL и Competency Questions

На этом этапе закладывается фундамент нашей базы знаний:
*   **`ONTOLOGY_TTL`**: Определяет базовые классы (`Drone`, `Camera`, `Pilot`, `Capability`) и отношения между ними (`hasPart`, `controls`, `hasCapability`). Это наш семантический "словарь".
*   **`SHACL_TTL`**: Задает формальные правила, которым должен соответствовать граф. Например, `DroneShape` требует, чтобы у каждого экземпляра класса `Drone` было как минимум одно свойство `hasCapability`.
*   **`CQS` (Competency Questions)**: Список вопросов на естественном языке, на которые наша система в итоге должна уметь отвечать. Это определяет целевой скоуп проекта.

### 2. Извлечение триплетов из текста с помощью LLM

Здесь неструктурированные текстовые документы (`DOCS`) обрабатываются для извлечения знаний:
*   **`EXTRACTION_SYSTEM`**: Системный промпт для LLM, который четко определяет задачу: извлечь триплеты "субъект-предикат-объект", их типы и уровень уверенности. Промпт требует на выходе **строго JSON**, что обеспечивает стабильность парсинга.
*   **`extract_triples`**: Функция отправляет текст в API OpenAI и получает JSON с извлеченными фактами.
*   Результатом является список словарей `all_triples`, готовый для преобразования в RDF.

### 3. Маппинг на онтологию и сериализация в TTL

Извлеченные "сырые" триплеты преобразуются в полноценный RDF-граф, согласованный с нашей онтологией:
*   Создается словарь `label_to_uri` для сопоставления текстовых меток классов и предикатов (например, "drone", "haspart") с их формальными URI (`ex:Drone`, `ex:hasPart`).
*   Создается новый RDF-граф (`rdflib.Graph`), в который добавляются как базовая онтология, так и новые триплеты.
*   Имена сущностей (например, "Falcon X") нормализуются в URI (`ex:FalconX`).
*   Итоговый граф сохраняется в файл `kg_from_llm.ttl`.

### 4. Валидация: SHACL + Reasoner

Это ключевой шаг для обеспечения качества и целостности графа:
*   **`validate_shacl`**: Функция использует библиотеку `pyshacl` для проверки графа из `kg_from_llm.ttl` на соответствие правилам из `ontology_shapes.ttl`. В консоль выводится отчет о найденных нарушениях.
*   **`reason_with_owlready`**: Для более глубокой логической проверки граф загружается в reasoner Pellet (через `owlready2`). Это позволяет выявить неконсистентные классы (например, если сущность одновременно принадлежит к двум несовместимым классам).
*   **`autofix_ttl` (Экспериментально)**: Предусмотрена функция, которая может попытаться автоматически исправить ошибки в TTL-файле, передав текст ошибки и сам граф в LLM.

### 5. Загрузка в Neo4j

Для масштабируемости и промышленного использования граф можно загрузить в графовую базу данных:
*   Функция `triples_to_neo` подключается к Neo4j.
*   Она преобразует RDF-триплеты в модель Labeled Property Graph (LPG): RDF-ресурсы становятся узлами (`Node`) с меткой `Entity`, а предикаты — именованными отношениями (`Relationship`).

### 6. Lightweight GraphRAG для ответов на вопросы

Эта секция реализует ядро RAG-процесса, адаптированного для графов:
1.  **Entity Linking (`link_entity`)**: Пользовательский вопрос (например, "Какая камера стоит на Falcon X?") анализируется для поиска упоминаний сущностей. С помощью нечеткого поиска (`rapidfuzz`) находятся наиболее вероятные узлы в графе (например, `ex:FalconX`).
2.  **Subgraph Retrieval (`subgraph_evidence`)**: От найденных "стартовых" узлов в графе собирается локальный подграф на глубину в несколько шагов. Этот подграф, содержащий факты, непосредственно связанные с сущностью из вопроса, и будет служить контекстом для ответа.
3.  **Grounded Generation (`answer_with_citations`)**: Собранные факты форматируются в виде пронумерованного списка (`[CID:0] FalconX -[hasPart]-> CamGo-4K`) и передаются в LLM вместе с вопросом. Промпт строго требует от модели генерировать ответ, используя **только эти факты** и обязательно **цитируя их по ID**. Это предотвращает галлюцинации и делает ответ верифицируемым.

### 7. Оценка по методологии MTRAGEval

Для оценки качества системы используется подход, основанный на фреймворке MTRAGEval:
*   **`load_mtrag_dialogs`**: Загружается тестовый набор диалогов, где для каждого вопроса есть "золотой" ответ (`gold`), содержащий ключевые слова.
*   **`run_mtrag_eval`**: Для каждого вопроса в диалоге запускается GraphRAG-пайплайн.
*   **Оцениваются две ключевые метрики**:
    *   **`retrieval_hit@10`**: Проверяет, содержат ли извлеченные из графа факты (контекст) ключевые слова из "золотого" ответа. Эта метрика оценивает качество retrieval-шага.
    *   **`groundedness`**: Проверяет, содержит ли финальный ответ LLM цитаты (`[CID:x]`). Это оценивает, насколько ответ "заземлен" на предоставленных фактах.
*   Результаты собираются в `pandas.DataFrame` для анализа.

## Как запустить

1.  **Установка зависимостей**:
    ```bash
    pip install openai rdflib owlready2 pyshacl networkx py2neo pandas scikit-learn tqdm rapidfuzz pyvis
    apt-get update && apt-get install -y default-jre # Необходимо для reasoner'а
    ```

2.  **Настройка переменных окружения**:
    Установите ваш API-ключ OpenAI. При необходимости настройте подключение к Neo4j.
    ```python
    os.environ["OPENAI_API_KEY"] = "sk-..."
    # NEO4J_URL, NEO4J_USER, NEO4J_PASS
    ```

3.  **Выполнение скрипта**:
    ```bash
    python ontology.py
    ```

4.  **Результаты**:
    *   В консоли будут выведены результаты каждого шага: отчеты валидации, сгенерированные ответы, итоговая таблица с метриками.
    *   Будут созданы файлы: `ontology_seed.ttl`, `ontology_shapes.ttl`, `kg_from_llm.ttl`.
    *   Будет сгенерирован интерактивный HTML-файл `ontology_graph.html` с визуализацией итогового графа знаний.

## Дальнейшие шаги

Текущая реализация является прочной основой для построения полноценного GraphRAG-пайплайна. Следующим логическим шагом может стать создание циклического взаимодействия между reasoner'ом и retriever'ом, где логический вывод (reasoning) может расширять граф новыми знаниями, которые затем используются на следующем шаге извлечения (retrieval) для ответа на более сложные, многошаговые вопросы.