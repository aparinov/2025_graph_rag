# README: Система извлечения знаний и ответов на вопросы на основе DeepSeek

## 1. Обзор проекта

Этот проект представляет собой комплексный пайплайн для построения и использования базы знаний (Knowledge Graph, KG) из научных текстов в формате PDF. Система использует большую языковую модель (LLM) **DeepSeek** для выполнения ключевых задач обработки естественного языка (NLP).

**Основная цель** — преобразовать неструктурированный текст из PDF-документа в структурированную онтологию и граф знаний, а затем использовать этот граф для создания системы ответов на вопросы (Question-Answering, QA).

Проект демонстрирует полный цикл работы с данными: от извлечения текста до оценки качества ответов модели, включая сравнение производительности с другими моделями, такими как GPT.

## 2. Архитектура пайплайна

Архитектура системы состоит из двух основных этапов: **построение графа знаний** и **система ответов на вопросы**.

### Этап 1: Построение графа знаний (Knowledge Graph Construction)

1.  **Извлечение данных**:
    *   Текст извлекается из исходного PDF-файла с помощью библиотеки `PyMuPDF`.
2.  **Предварительная обработка текста**:
    *   Текст разбивается на абзацы для дальнейшей гранулярной обработки.
    *   Проводится лемматизация и извлечение ключевых терминов с помощью `spaCy` для первичного анализа содержимого.
3.  **Извлечение онтологии с помощью DeepSeek**:
    *   **Категоризация**: Модель DeepSeek анализирует абзацы и извлекает высокоуровневые категории (например, 'Organic Chemistry', 'Chemical Reactions').
    *   **Извлечение терминов**: Из текста извлекаются конкретные научные термины.
    *   **Построение таксономии**: Устанавливаются иерархические связи типа `isA` (является подклассом) между терминами и категориями. Это делается путем прямого запроса к модели для каждой пары (термин, категория).
4.  **Формирование графа знаний**:
    *   На основе таксономии создается базовый граф (`isA` связи).
    *   Из текста напрямую извлекаются факты в виде триплетов `(субъект, предикат, объект)`.
    *   Все извлеченные связи объединяются в единый граф знаний.
5.  **Визуализация**:
    *   Полученные графы (таксономия и полный граф знаний) визуализируются с помощью `networkx` и `matplotlib` для наглядного представления структуры знаний. Узлы и ребра графа раскрашиваются для лучшей читаемости.

### Этап 2: Система ответов на вопросы (Question-Answering System)

1.  **Классификация вопроса**:
    *   Пользовательский вопрос сначала классифицируется для определения его тематической принадлежности (например, "химия", "физика").
2.  **Идентификация релевантных узлов**:
    *   В рамках определенной темы модель находит наиболее релевантные концепции (узлы) в графе знаний, связанные с вопросом.
3.  **Фильтрация фактов**:
    *   Система извлекает подмножество фактов (триплетов) из графа знаний, которые напрямую относятся к релевантным узлам.
4.  **Генерация ответа**:
    *   Отфильтрованные факты и исходный вопрос передаются модели DeepSeek с инструкцией сгенерировать ответ, основываясь **исключительно** на предоставленной информации.
5.  **Оценка качества**:
    *   **Автоматические метрики**: Качество сгенерированного ответа оценивается с помощью лексических метрик **BLEU** и **ROUGE-L**, которые измеряют степень совпадения с ожидаемым ответом.
    *   **Оценка моделью**: Сама модель DeepSeek используется для оценки корректности и релевантности сгенерированного ответа по шкале от 1 до 5.
    *   **Точность классификации**: Оценивается точность определения темы вопроса.

## 3. Суть кода и ключевые компоненты

### 3.1. Загрузка и предварительная обработка (`01_data_extraction.ipynb`)

*   **Зависимости**: `PyMuPDF` для работы с PDF, `spaCy` для NLP-задач, `tqdm` для индикаторов прогресса.
*   `extract_text_from_pdf(pdf_path)`: Функция для чтения текста из PDF-файла.
*   `lemmatize_terms(text)`: Использует `spaCy` для токенизации, лемматизации и удаления стоп-слов, позволяя выделить ключевые термины.
*   `split_into_paragraphs(text)`: Разделяет сплошной текст на абзацы, что необходимо для более точной обработки моделью.

### 3.2. Взаимодействие с API DeepSeek (`02_api_interaction.ipynb`)

*   Используется официальный клиент `openai` с указанием `base_url="https://api.deepseek.com"`.
*   Для аутентификации требуется `api_key`.
*   Функция `deepseek_chat` является оберткой для удобного вызова модели.

### 3.3. Построение таксономии и графа знаний (`03_knowledge_graph.ipynb`)

*   `extract_categories_with_gpt(paragraphs)`: Отправляет батч абзацев в DeepSeek для извлечения высокоуровневых категорий.
*   `ask_isA_relation(term, category)`: Ключевая функция для построения таксономии. Задает модели прямой вопрос: "Является ли 'термин' подклассом 'категории'?" и ожидает ответ "Yes" или "No".
*   На основе ответов "Yes" формируются связи `isA` и строится направленный граф (`nx.DiGraph`).
*   `extract_ontology_triples(text)`: Извлекает из текста факты в виде триплетов `(субъект, предикат, объект)`, формируя основу для графа знаний.
*   **Визуализация**: Графы визуализируются с помощью `networkx` и `matplotlib`, узлы окрашиваются в зависимости от их типа (категория, термин, реакция), а ребра — в зависимости от типа предиката.

### 3.4. Система QA и оценка (`04_qa_evaluation.ipynb`)

*   **Многошаговый QA пайплайн**:
    1.  `classify_question_topic()`: Определяет тему вопроса.
    2.  `classify_question_node_in_topic()`: Находит релевантный узел в графе.
    3.  `answer_question_from_facts()`: Генерирует ответ на основе отфильтрованных фактов.
*   **Оценка**:
    *   `evaluate_answer_with_gpt()`: Функция, где модель сама оценивает сгенерированный ею же ответ на корректность и релевантность.
    *   Используются стандартные метрики `BLEU` (из `nltk`) и `ROUGE-L` (из `rouge-score`) для оценки лексического совпадения.
    *   Результаты собираются в `pandas.DataFrame` и анализируются.

## 4. Результаты и выводы

На основе предоставленной информации можно сделать следующие выводы:

*   **Качество ответов**: DeepSeek демонстрирует высокую корректность и релевантность ответов, когда ему предоставляется правильное подмножество фактов. Это подтверждает его способность к логическому выводу на основе ограниченного контекста.
*   **Слабость в классификации**: Точность классификации тем у DeepSeek оказалась значительно ниже, чем у GPT (упомянуто 66.7% у GPT). Это указывает на то, что для задач с нулевым или малым количеством примеров (zero/few-shot classification) модель может требовать дополнительной настройки или более четких промптов.
*   **Лексические метрики**: Более низкие значения метрик **BLEU** и **ROUGE-L** у DeepSeek по сравнению с ожидаемыми результатами говорят о том, что сгенерированные ответы могут отличаться по формулировкам от эталонных, даже если семантически они верны. Модель может быть менее склонна к дословному копированию фраз из контекста.

## 5. Как запустить

1.  **Установите зависимости**:
    ```bash
    pip install PyMuPDF tqdm spacy openai pandas networkx matplotlib seaborn rouge-score nltk
    python -m spacy download en_core_web_sm
    ```

2.  **Настройте окружение**:
    *   Поместите ваш PDF-файл в корневую директорию проекта.
    *   Создайте файлы `extract_terms.txt` и `categories.txt` или убедитесь, что код генерирует их корректно.
    *   Укажите ваш API-ключ от DeepSeek в коде:
        ```python
        client = OpenAI(api_key="ВАШ_API_КЛЮЧ", base_url="https://api.deepseek.com")
        ```

3.  **Запустите ячейки**:
    *   Код представлен в виде ячеек для Jupyter Notebook или Google Colab. Выполняйте их последовательно.
    *   На шагах, где требуется загрузка файлов (`files.upload()`), загрузите необходимые данные.