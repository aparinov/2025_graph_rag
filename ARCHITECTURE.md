# Архитектура проекта

Проект исследует несколько способов построения графа знаний из фармацевтических инструкций и последующего поиска/ответов через Neo4j. Все варианты используют LLM для извлечения сущностей и связей, но отличаются качеством результатов и степенью контроля структуры.

## Общая инфраструктура
- **Neo4j** поднимается через `docker-compose.yml`; пароли и плагины (APOC) задаются на уровне сервиса. В рабочей директории есть тома `neo4j/` для данных, конфигурации и плагинов.
- **Python/uv**: зависимости управляются `pyproject.toml` + `uv.lock`, контейнерное окружение собирается с `Dockerfile` (образ `ghcr.io/astral-sh/uv:python3.12-bookworm-slim`).
- **Переменные окружения**: `.env` хранит ключи `OPENAI_API_KEY`, а также доступ к Neo4j. Параметры прокси и альтернативных LLM (например, GigaChat) читаются из тех же переменных.
- **Исходные данные**: типовой вход — PDF-инструкции (`nurofen.pdf`, `nurofen2.pdf`) и сгенерированные результаты (`res.json`) для отладки.

## Базовый pipeline (файл `main.py`)

### Назначение
Интерактивный Gradio-приложение, которое:
1. Ингестирует отдельный PDF через LLM в Neo4j.
2. Позволяет задавать вопросы по графу через LangChain + OpenAI/GigaChat.

### Поток данных
1. **Загрузка и разбиение**  
   - Файлы читает `UnstructuredPDFLoader`.  
   - Текст бьётся `CharacterTextSplitter` (512 символов с overlap 128), формируя список `Document`.
2. **Извлечение сущностей и связей** (`ingest_with_iterative_extraction`)  
   - Для каждого чанка запускается prompt `entity_extraction_prompt` через выбранный LLM (OpenAI/GigaChat).  
   - Ответ парсится через `json_repair`, валидные сущности (`id`, `type`, `properties`) сразу мержатся в Neo4j: `MERGE (n:\`Type\` {id}) SET n += properties`.  
   - Второй проход берёт все найденные пары сущностей в чанке, вызывает `relationship_extraction_prompt`, записывает рёбра `MERGE (a)-[:TYPE]->(b)` с атрибутами.  
   - После завершения все узлы связываются с документом `(:Document {id})` через `[:APPEARS_IN]`.
3. **Обновление схему Neo4j**  
   - `graph.refresh_schema()` запускается вручную после инжеста, так как при создании `Neo4jGraph` отключён auto-refresh.
4. **Интерфейс вопрос-ответ**  
   - Gradio UI: загрузка PDF, выбор LLM-провайдера, чат.  
   - Функция `predict_with_rag` строит `GraphCypherQAChain`:  
     - Для генерации Cypher всегда выбирается OpenAI (если доступен) через `create_llm_client(..., for_cypher=True)`.  
     - Для финального ответа используется выбранный пользователем провайдер.  
   - Результат возвращается в чат; история сохраняется на клиенте.

### Ключевые особенности
- Простой двухпроходный extraction → LLM вызывает Neo4j напрямую во время обработки.  
- Нет проверки на дубли: похожие сущности/связи могут появляться несколько раз.  
- Поддержка нескольких LLM за счёт фабрики `create_llm_client`.  
- Позволяет очищать граф (`clear_neo4j`) из интерфейса.

## Улучшенный pipeline (файл `improved_pipeline.py`)

### Цель
Уменьшить число дубликатов и стабилизировать извлечение, сохранив фокус на той же предметной области (фармацевтические инструкции).

### Основные компоненты
1. **Параметры**  
   - Жёстко заданные `CHUNK_SIZE=800`, `CHUNK_OVERLAP=150`, `BATCH_SIZE=5`.  
   - Словари допустимых типов сущностей (`ENTITY_TYPES`) и отношений (`RELATION_TYPES`) задают доменную схему.
2. **StableEntityExtractor**  
   - `ChatOpenAI(gpt-3.5-turbo)` с жёстким промптом (строгий JSON, ограничение длины чанка до 1500 символов).  
   - Извлечение батчами через `ThreadPoolExecutor`, что ускоряет обработку PDF.  
   - Нормализация ответа: очищение от markdown, фильтрация по допустимым типам, обрезка контекста.
3. **FastDeduplicator**  
   - Пытается загрузить OpenAI embeddings (`text-embedding-3-small`).  
   - Дедупликация двухступенчатая:  
     - Сначала группировка fuzzy matching (`rapidfuzz`, `token_sort_ratio`).  
     - Для крупных групп и при доступности эмбеддингов — кластеризация по косинусному сходству.  
   - Для каждой группы создаётся каноническая сущность (UUID, агрегация контекстов, счётчик членов); строится карта соответствий индекс → канонический ID.
4. **RelationExtractor**  
   - Отдельный промпт для LLM, использующий список допустимых отношений.  
   - Возвращает JSON c `source`, `target`, `relation`, `confidence`, `chunk_idx`.  
   - Фильтрует результаты, оставляя только отношения с доверием > 0.5.
5. **Neo4jWriter**  
   - Использует `Neo4jGraph` (LangChain), но операции выполняет ручными Cypher-запросами батчами.  
   - Записывает `(:Document)` с метаданными (кол-во чанков, timestamp), затем `MERGE` сущностей и `[:APPEARS_IN]`.  
   - При создании связей ориентируется на `name`, а не ID, поэтому важно, чтобы имена были очищены в дедупликаторе.
6. **ImprovedPipeline.process_pdf**  
   - Собирает все компоненты воедино: загрузка → извлечение → дедуп → отношения → запись → сводка.  
   - Логирует время выполнения и количество найденных сущностей/отношений.  
   - CLI-интерфейс в `main()` запускает обработку `nurofen.pdf`, выводя статистику.  
   - Пример итоговых данных — `res.json` (распространённый формат: канонические сущности, кандидаты связей, подтверждённые рёбра).

### Улучшения по сравнению с базовым подходом
- Строгая доменная схема ограничивает «разброс» типов.  
 - Параллельная обработка чанков ускоряет извлечение.  
 - Дедупликация на основе fuzzy + embeddings уменьшает количество повторов.  
 - Хранение счётчиков и контекстов помогает при анализе качества.  
 - Отделение извлечения, нормализации и записи делает pipeline модульным, удобным для тестирования и доработки.

## Онтологический pipeline (файл `ontology_rag.py`)

### Мотивация
Автоматически формировать KG прямо из онтологии OWL/Turtle, чтобы строго контролировать структуру графа и её соответствие предметной области. Использует стек `neo4j-graphrag`.

### Шаги
1. **Настройка**  
   - Конфигурация загружается через Pydantic `Settings` из `.env` (`NEO4J_URI`, `OPENAI_API_KEY`, `NEO4J_USER`, `NEO4J_PASSWORD`).  
   - Включён `nest_asyncio` для запуска asyncio внутри REPL/ноутбука.
2. **Подготовка текста**  
   - `load_and_chunk_pdf` аналогично прошлым подходам, но chunk size 1000/overlap 200.  
   - Очищает whitespace.
3. **Генерация/загрузка онтологии** (`generate_ontology`)  
   - Если `pharma_ontology.ttl` отсутствует или запрошено `overwrite`, LLM (`gpt-4o`) генерирует TBox-онтологию на основе текстового примера.  
   - Жёсткий промпт требует валидный Turtle, без individuals, с двуязычными лейблами и доменно-ориентированными классами/свойствами.  
   - Файл сохраняется в корне репозитория.
4. **Преобразование онтологии в схему Neo4j GraphRAG**  
   - RDF парсится через `rdflib.Graph`.  
   - `build_schema_from_ontology` проходит по `owl:Class` → создаёт `SchemaEntity` (с описаниями и datatype-свойствами), по `owl:ObjectProperty` → `SchemaRelation` и возможные триплеты `domain → property → range`.  
   - Полученная схема используется как вход в KG-builder.
5. **Построение графа знаний**  
   - Используется `SimpleKGPipeline` из `neo4j_graphrag.experimental.pipeline`.  
   - Компоненты:  
     - `OpenAILLM` (`gpt-4o`, json_object формат, `max_tokens=10000`) — управляет извлечением по схеме.  
     - `FixedSizeSplitter` (1500/150).  
     - `OpenAIEmbeddings` для возможных векторных индексов.  
   - Pipeline запускается через `await kg_builder.run_async(text=full_text)`; Neo4j драйвер открывается/закрывается контекстно (`Neo4jKGClient`).
6. **Подготовка к RAG (опционально)**  
   - Код для создания векторного индекса (`create_vector_index`, `upsert_vector`) и финального поиска через `GraphRAG` закомментирован, но показывает, как продолжить после построения KG.  
   - Предполагается дополнение VectorRetriever + GraphRAG для ответа на вопросы по фактическому контенту онтологически выровненного графа.

### Особенности и отличия
- Схема KG формируется из онтологии, а не из ad-hoc типов в коде.  
- Используется библиотека `neo4j-graphrag`, которая ожидает строгие `SchemaEntity`/`SchemaRelation`.  
- Текст для онтологии берётся из входного документа, что позволяет адаптировать словарь под конкретный набор инструкций.  
- Вся обработка выполняется асинхронно; важно запускать через `asyncio.run(main())`.  
- Требует большего числа внешних зависимостей (rdflib, neo4j-graphrag, pydantic-settings).

## Как выбирать подход
- **Базовый** — быстрый способ проверить идею и продемонстрировать end-to-end поток «PDF → Neo4j → QA». Простая настройка, но страдает от дубликатов и нестабильного вывода LLM.  
- **Улучшенный** — баланс между гибкостью и качеством. Добавляет контроль типов, параллельность и дедупликацию, даёт более чистый граф. Хорошо подходит для пакетной загрузки инструкций.  
- **Онтологический** — для строгих требований к структуре и интеграции с классическими ontologies. Предоставляет возможность совместить GraphRAG и векторный поиск в рамках определённой схемы.

Каждый pipeline можно развивать независимо: например, базовый — улучшать UI, улучшенный — расширять словари типов и правила дедупликации, онтологический — наращивать онтологию и подключать поиск/генерацию ответов.
